{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRuA7250YgEP"
      },
      "source": [
        "# Hacka (midterm) thon \n",
        "\n",
        "## Detecting Malicious URLs \n",
        "\n",
        "Today you are invited to repeat the path of researchers Detecting Malicious URLs.\n",
        "An anonymized 120-day subset of our ICML-09 data set.\n",
        "The data set consists of about 2.4 million URLs (examples) and 3.2 million features. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4A6jSO-YgET"
      },
      "source": [
        "#### 1. Download data using link below\n",
        "[Download Dataset](http://www.sysnet.ucsd.edu/projects/url/url_svmlight.tar.gz)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_osfLe3JYgEU"
      },
      "source": [
        "#### 2. Description of Data (SVM-light)\n",
        "Uncompressing the archive url_svmlight.tar.gz will yield a directory url_svmlight/ containing the following files:\n",
        "\n",
        "1. **FeatureTypes**. A text file list of feature indices that correspond to real-valued features.\n",
        "2. **DayX.svm** (where X is an integer from 0 to 120) --- The data for day X in SVM-light format. A label of +1 corresponds to a malicious URL and -1 corresponds to a benign URL.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnX0qdpRYgEV"
      },
      "source": [
        "#### 3. Read article\n",
        "Please familiarize yourself with original research article. It will give you required context.\n",
        "\n",
        "*\"**Beyond Blacklists: Learning to Detect Malicious Web Sites from Suspicious URLs**\"* \n",
        "\n",
        "*Justin Ma, Lawrence K. Saul, Stefan Savage, Geoffrey M. Voelker* "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtC1N81FYgEV"
      },
      "source": [
        "## Demo part"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEEiVGQnYgEW"
      },
      "source": [
        "#### 1. Upload data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uVtZiJo5YgEW",
        "outputId": "c7883e4b-e983-44f4-e4cc-84f02938a75a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 121 files\n"
          ]
        }
      ],
      "source": [
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_svmlight_file\n",
        "files = glob.glob('./url_svmlight/url_svmlight/*.svm')\n",
        "print(\"There are %d files\" % len(files))\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZm3ezWcYgEY"
      },
      "source": [
        "#### 2. What is inside"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "19c1FeTAYgEZ"
      },
      "outputs": [],
      "source": [
        "import tarfile\n",
        "from sklearn.datasets import load_svmlight_file\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cwq3LsiRYgEa",
        "outputId": "41bbd7dc-19aa-4b62-b0b0-91250af65196"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "extracting url_svmlight,f size 0\n",
            "extracting url_svmlight/Day33.svm,f size 18674876\n",
            "extracting url_svmlight/Day32.svm,f size 18599211\n",
            "extracting url_svmlight/Day53.svm,f size 18963938\n",
            "extracting url_svmlight/Day20.svm,f size 18633460\n",
            "extracting url_svmlight/Day7.svm,f size 18777054\n",
            "extracting url_svmlight/Day117.svm,f size 18106370\n",
            "max X = 3231952, max y dimension = 20000\n"
          ]
        }
      ],
      "source": [
        "uri = ('./url_svmlight.tar.gz')\n",
        "tar = tarfile.open(uri, \"r:gz\")\n",
        "max_obs = 0\n",
        "max_vars = 0\n",
        "i = 0\n",
        "split = 5\n",
        "for tarinfo in tar:\n",
        "    print(\"extracting %s,f size %s\" % (tarinfo.name, tarinfo.size))\n",
        "    if tarinfo.isfile():\n",
        "        f = tar.extractfile(tarinfo.name)\n",
        "        X,y = load_svmlight_file(f)\n",
        "        max_vars = np.maximum(max_vars, X.shape[0])\n",
        "        max_obs = np.maximum(max_obs, X.shape[1])\n",
        "    if i > split:\n",
        "        break\n",
        "    i+=1\n",
        "print(\"max X = %s, max y dimension = %s\" % (max_obs, max_vars)) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7f012MXbYgEb"
      },
      "source": [
        "#### 3. What is inside"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UqKaqu7eYgEb",
        "outputId": "7aad048c-3d3c-4d4d-9caf-6e5b0fedddd1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.96      1.00      0.98     13700\n",
            "           1       0.99      0.90      0.94      6300\n",
            "\n",
            "    accuracy                           0.97     20000\n",
            "   macro avg       0.97      0.95      0.96     20000\n",
            "weighted avg       0.97      0.97      0.96     20000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "classes = [-1,1] # 1_:url- safety, -1: url- non-safety\n",
        "sgd = SGDClassifier(loss='log')\n",
        "n_features = 3231952\n",
        "split = 5\n",
        "i = 0\n",
        "for tarinfo in tar:\n",
        "    if i > split:\n",
        "        break\n",
        "    if tarinfo.isfile():\n",
        "        f = tar.extractfile(tarinfo.name)\n",
        "        X,y = load_svmlight_file(f,n_features=n_features)\n",
        "        if i < split:\n",
        "            sgd.partial_fit(X,y, classes = classes)\n",
        "        if i == split:\n",
        "            print (classification_report(sgd.predict(X),y))\n",
        "    i+=1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iClXlk0iYgEc"
      },
      "source": [
        "## Midterm (Part 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNGQm2m1YgEc"
      },
      "source": [
        "### Grading criteria\n",
        "- Complete solution - 60%\n",
        "- F1 Score - 40%\n",
        "    - The first 10 results get 40%\n",
        "    - Worst result get 20%\n",
        "    - All others are on a scale between them"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1iX7qzAYgEc"
      },
      "source": [
        "### Deadline\n",
        "20:00 MSK, April 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIaEuJ22YgEc"
      },
      "source": [
        "#### 1. Train, test\n",
        "- Upload data (you can use template above)\n",
        "- Separate your dataset into train and test subsets of observations\n",
        "- Use the 8:2 ratio: 80% train set, 20% test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z1YNWBRbYgEd"
      },
      "outputs": [],
      "source": [
        "from random import random\n",
        "\n",
        "def train_test_split(train_size = 0.8):\n",
        "    train = open('./url_svmlight/train.svm','w')\n",
        "    test  = open('./url_svmlight/test.svm','w')\n",
        "    summ = 0\n",
        "    for i in range(121):\n",
        "        inn = open('./url_svmlight/url_svmlight/Day' + str(i) + '.svm','r')\n",
        "        \n",
        "        print(\"file: \" + str(i))\n",
        "        \n",
        "        q = [0, 0]\n",
        "        \n",
        "        for line in inn:\n",
        "            a = line.split()\n",
        "            if(a[0] == \"-1\"):\n",
        "                q[0] += 1\n",
        "            else:\n",
        "                q[1] += 1\n",
        "        \n",
        "        inn.close()\n",
        "        summ += q[0] + q[1]\n",
        "        check = [int(train_size * q[0]),int(train_size * q[1])]\n",
        "        start = [0, 0]\n",
        "        \n",
        "        inn = open('./url_svmlight/url_svmlight/Day' + str(i) + '.svm','r')\n",
        "        \n",
        "        if (train_size * q[0]) % 1 >=0.5:\n",
        "            check[0] += 1\n",
        "        if (train_size * q[1]) % 1 >=0.5:\n",
        "            check[1] += 1\n",
        "        for line in inn:\n",
        "            a = line.split()\n",
        "\n",
        "            rand = random()\n",
        "            if rand > 0.5:\n",
        "                if a[0] == \"-1\":\n",
        "                    if start[0] + 1 <= check[0]:\n",
        "                        train.write(line)\n",
        "                        train.write(\"\\n\")\n",
        "                        start[0] += 1\n",
        "                    else:\n",
        "                        test.write(line)\n",
        "                        test.write(\"\\n\")\n",
        "                        q[0] -= 1\n",
        "                else:\n",
        "                    if start[1] + 1 <= check[1]:\n",
        "                        train.write(line)\n",
        "                        train.write(\"\\n\")\n",
        "                        start[1] += 1\n",
        "                    else:\n",
        "                        test.write(line)\n",
        "                        test.write(\"\\n\")\n",
        "                        q[1] -= 1\n",
        "            else:\n",
        "                if(a[0] == \"-1\"):\n",
        "                    if q[0] > check[0]:\n",
        "                        test.write(line)\n",
        "                        test.write(\"\\n\")\n",
        "                        q[0] -= 1\n",
        "                    else :\n",
        "                        train.write(line)\n",
        "                        train.write(\"\\n\")\n",
        "                        start[0] += 1\n",
        "                else:\n",
        "                    if q[1] > check[1]:\n",
        "                        test.write(line)\n",
        "                        test.write(\"\\n\")\n",
        "                        q[1] -= 1\n",
        "                    else :\n",
        "                        train.write(line)\n",
        "                        train.write(\"\\n\")\n",
        "                        start[1] += 1\n",
        "        print(\"finish: \" + str(i))\n",
        "    print(summ)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HRCefZ31YgEe"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_svmlight_file\n",
        "from sklearn.linear_model import Perceptron\n",
        "import numpy as np\n",
        "\n",
        "train_test_split()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "data = None\n",
        "n_features = 3231961\n",
        "\n",
        "\n",
        "data, target = load_svmlight_file(\"./url_svmlight/train.svm\",n_features=n_features)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "bEd8iJCFYgEe"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdy5sZaWYgEe"
      },
      "source": [
        "#### 2. Find out whether it is possible to reduce the dimension?\n",
        "\n",
        "There are three selected methods considered for dimensionality reduction - FA, sparce PCA and selection best features.\n",
        "\n",
        "\"calculate_bartlett_sphericity\" and \"calculate_kmo\" helps to identify applicability for Factor Analysis. If these tests are negative -> there is high probability of multicolinearity (det < 0.00001)\n",
        "\n",
        "therefore these two test are provided here\n",
        "\n",
        "but it invokes memory allocation problem -> the data is too heavy to apply FA or sparse PCA directly\n",
        "\n",
        "therefore selection of best features are chosen as a dimensionality reduction algorithm.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "from factor_analyzer import FactorAnalyzer\n",
        "from factor_analyzer.factor_analyzer import calculate_bartlett_sphericity\n",
        "\n",
        "chi_square_value,p_value=calculate_bartlett_sphericity(data)\n",
        "print(chi_square_value, p_value)\n",
        "\n",
        "from factor_analyzer.factor_analyzer import calculate_kmo\n",
        "\n",
        "kmo_all,kmo_model=calculate_kmo(data)\n",
        "print(kmo_model)\n"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ODRM2jpaYgEf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "## turn \"-1\" -> 0, \"1\" -> 1\n",
        "positive_target = [(int(x)+1)//2 for x in target]"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "-mEq7Fi9YgEf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\kolma\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:115: UserWarning: Features [0 0 0 ... 0 0 0] are constant.\n",
            "  UserWarning)\n",
            "C:\\Users\\kolma\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:116: RuntimeWarning: invalid value encountered in true_divide\n",
            "  f = msb / msw\n",
            "C:\\Users\\kolma\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\validation.py:71: FutureWarning: Pass zero_based=False as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
            "  FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.feature_selection import f_classif\n",
        "\n",
        "X, y = data, positive_target\n",
        "\n",
        "data  = SelectKBest(f_classif, k=10000).fit_transform(X, y)\n",
        "\n",
        "from sklearn.datasets import dump_svmlight_file\n",
        "dump_svmlight_file(data, y, \"labeled_features.txt\",False)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "r9NgEoOmYgEf",
        "outputId": "4374c1f5-5025-46f5-e6aa-fd6d57b1ba53"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": "<1916904x10000 sparse matrix of type '<class 'numpy.float64'>'\n\twith 198620398 stored elements in Compressed Sparse Row format>"
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Doyj9VFBYgEf",
        "outputId": "4e267477-0055-4de9-dd83-2da4f78b1803"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1816904, 10000)\n",
            "(100000, 10000)\n",
            "________________________________________________________________________________\n",
            "Training: \n",
            "RandomForestClassifier()\n",
            "train time: 21078.669s\n",
            "test time:  6.635s\n",
            "accuracy:   0.985\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        -1.0   0.999582  0.998898  0.999240   1284068\n",
            "         1.0   0.997767  0.999151  0.998459    632836\n",
            "\n",
            "    accuracy                       0.998982   1916904\n",
            "   macro avg   0.998674  0.999025  0.998849   1916904\n",
            "weighted avg   0.998983  0.998982  0.998982   1916904\n",
            "\n"
          ]
        }
      ],
      "source": [
        "## Train data + Valid data\n",
        "\n",
        "from sklearn.datasets import load_svmlight_file\n",
        "\n",
        "X, y = data, target\n",
        "\n",
        "train_X = X[0:1816904]\n",
        "train_y = y[0:1816904]\n",
        "test_X = X[1816904:]\n",
        "test_y = y[1816904:]\n",
        "print(train_X.shape)\n",
        "print(test_X.shape)\n",
        "\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "\n",
        "def pipeline(clf):\n",
        "    print('_' * 80)\n",
        "    print(\"Training: \")\n",
        "    print(clf)\n",
        "    start_time = time()\n",
        "    clf.fit(train_X, train_y)\n",
        "    train_time = time() - start_time\n",
        "    print(\"train time: %0.3fs\" % train_time)\n",
        "    start_time = time()\n",
        "    pred = clf.predict(test_X)\n",
        "    test_time = time() - start_time\n",
        "    print(\"test time:  %0.3fs\" % test_time)\n",
        "    score = metrics.accuracy_score(test_y, pred)\n",
        "    print(\"accuracy:   %0.3f\" % score)\n",
        "    clf_descr = str(clf).split('(')[0]\n",
        "    return clf_descr, score, train_time, test_time\n",
        "\n",
        "clf = RandomForestClassifier(n_estimators=100)\n",
        "\n",
        "pipeline(clf)\n",
        "\n",
        "print (classification_report(clf.predict(data),target, digits = 6))"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "2vVXT_enYgEg",
        "outputId": "d875c58a-88b5-4797-9911-a704940a90bc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Train data + test data]\n",
        "\n",
        "RandomForestClassifier is a nice classifier in terms of high dimensionality, therefore it is chosen to be a main model.\n",
        "\n",
        "NOTE: it takes much time to train the classifier, while other classifiers are much faster, but since F1-score is important the RandomForest Classifier is chosen."
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "sWIuL9WNYgEg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "data = None\n",
        "n_features = 3231961\n",
        "\n",
        "data_train, target_train = load_svmlight_file(\"./url_svmlight/train.svm\",n_features=n_features)\n",
        "data_test, target_test = load_svmlight_file(\"./url_svmlight/test.svm\",n_features=n_features)\n",
        "positive_target_train = [(int(x)+1)//2 for x in target_train]\n",
        "positive_target_test = [(int(x)+1)//2 for x in target_test]"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "DPJPu5axYgEg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start train transform\n",
            "Start test transform\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\kolma\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:115: UserWarning: Features [0 0 0 ... 0 0 0] are constant.\n",
            "  UserWarning)\n",
            "C:\\Users\\kolma\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:116: RuntimeWarning: invalid value encountered in true_divide\n",
            "  f = msb / msw\n",
            "C:\\Users\\kolma\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\validation.py:71: FutureWarning: Pass zero_based=False as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
            "  FutureWarning)\n",
            "C:\\Users\\kolma\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\validation.py:71: FutureWarning: Pass zero_based=False as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
            "  FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "import tqdm\n",
        "\n",
        "X_train, y_trian = data_train, positive_target_train\n",
        "X_test, y_test = data_test, positive_target_test\n",
        "\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_classif\n",
        "\n",
        "skbest = SelectKBest(f_classif, k=10000)\n",
        "\n",
        "print(\"Start train transform\")\n",
        "best_data_train  = skbest.fit_transform(X_train, y_trian)\n",
        "print(\"Start test transform\")\n",
        "best_data_test  = skbest.transform(X_test)\n",
        "\n",
        "from sklearn.datasets import dump_svmlight_file\n",
        "dump_svmlight_file(best_data_train, y_trian, \"labeled_best_data_train.txt\",False)\n",
        "dump_svmlight_file(best_data_test, y_test, \"labeled_best_data_test.txt\",False)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "PF8tUF7tYgEg",
        "outputId": "3d4d9931-4334-4edd-d830-ed828e69fc2c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": "<1916904x10000 sparse matrix of type '<class 'numpy.float64'>'\n\twith 198620398 stored elements in Compressed Sparse Row format>"
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_data_train"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ZORq2LZwYgEh",
        "outputId": "d74d8242-ece2-4180-8b02-4e2fa545c310"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "________________________________________________________________________________\n",
            "Training: \n",
            "RandomForestClassifier()\n",
            "train time: 20522.377s\n",
            "test time:  26.493s\n",
            "accuracy:   0.993\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0   0.994208  0.995154  0.994681    320490\n",
            "         1.0   0.990198  0.988295  0.989245    158736\n",
            "\n",
            "    accuracy                       0.992882    479226\n",
            "   macro avg   0.992203  0.991725  0.991963    479226\n",
            "weighted avg   0.992880  0.992882  0.992881    479226\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import load_svmlight_file\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def get_data(name):\n",
        "    data = load_svmlight_file(name)\n",
        "    return data[0], data[1]\n",
        "\n",
        "best_data_train, y_trian = get_data(\"labeled_best_data_train.txt\")\n",
        "best_data_test, y_test  = get_data(\"labeled_best_data_test.txt\")\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import metrics\n",
        "from time import time\n",
        "\n",
        "\n",
        "def pipeline(clf):\n",
        "    print('_' * 80)\n",
        "    print(\"Training: \")\n",
        "    print(clf)\n",
        "    start_time = time()\n",
        "    clf.fit(best_data_train, y_trian)\n",
        "    train_time = time() - start_time\n",
        "    print(\"train time: %0.3fs\" % train_time)\n",
        "    start_time = time()\n",
        "    pred = clf.predict(best_data_test)\n",
        "    test_time = time() - start_time\n",
        "    print(\"test time:  %0.3fs\" % test_time)\n",
        "    score = metrics.accuracy_score(y_test, pred)\n",
        "    print(\"accuracy:   %0.3f\" % score)\n",
        "    clf_descr = str(clf).split('(')[0]\n",
        "    return clf_descr, score, train_time, test_time\n",
        "\n",
        "\n",
        "clf = RandomForestClassifier(n_estimators=100)\n",
        "\n",
        "pipeline(clf)\n",
        "\n",
        "print(classification_report(clf.predict(best_data_test),y_test, digits = 6))"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "-zlLw7PtYgEh",
        "outputId": "62a625fd-9309-4450-dc39-58df8c44fd4b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# from scipy.sparse.linalg import svds\n",
        "# S,U,V = svds(data)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "LkE2mScxYgEh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# U"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "KomIeXreYgEi",
        "outputId": "ab9faa12-5a31-4cf2-b133-a7ff844cc999"
      },
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": "array([ 1222.53889114,  1270.00412156,  1369.9157008 ,  2054.26508337,\n        2702.16794462, 11461.08949531])"
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFo0uiBrYgEi"
      },
      "source": [
        "#### 3. Create a model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GVZBCqkYYgEi",
        "outputId": "8ba14b21-f53e-4060-c9cc-7317e7631880"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/faritgaleev/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
            "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "PassiveAggressiveClassifier(C=1.0, average=False, class_weight=None,\n",
              "              fit_intercept=True, loss='hinge', max_iter=None, n_iter=None,\n",
              "              n_jobs=1, random_state=None, shuffle=True, tol=None,\n",
              "              verbose=0, warm_start=False)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.linear_model import PassiveAggressiveClassifier\n",
        "pac = PassiveAggressiveClassifier()\n",
        "pac.fit(data,target)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQRMxeWeYgEi"
      },
      "source": [
        "#### 4. Get the quality\n",
        "- precision\n",
        "- recall\n",
        "- f1-score\n",
        "- support "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4ReQfN_YgEj",
        "outputId": "6eed8513-49b5-4f93-86c3-40f00227f922"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "             precision    recall  f1-score   support\n",
            "\n",
            "       -1.0   0.993186  0.990672  0.991927    321609\n",
            "        1.0   0.981064  0.986131  0.983591    157617\n",
            "\n",
            "avg / total   0.989199  0.989178  0.989185    479226\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "data, target = load_svmlight_file(\"./url_svmlight/test.svm\",n_features=n_features)\n",
        "print (classification_report(pac.predict(data),target, digits = 6))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "colab": {
      "name": "midterm.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}